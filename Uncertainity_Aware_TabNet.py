# -*- coding: utf-8 -*-
"""Final_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tUhk27cDhYeRZAj1HvzyqYzWOtRTOYnO
"""

# Install libraries
!pip install pytorch-tabnet ctgan optuna imbalanced-learn torch pandas numpy scikit-learn matplotlib seaborn

# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from pytorch_tabnet.tab_model import TabNetClassifier
import optuna
from optuna import Trial
import torch
import torch.nn as nn
from ctgan import CTGAN
import pickle

# Set seeds
torch.manual_seed(42)
np.random.seed(42)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Load and preprocess
data = pd.read_csv('/content/fetal_health.csv')
features_to_drop = [
    'fetal_movement', 'histogram_width', 'histogram_max', 'mean_value_of_long_term_variability',
    'histogram_number_of_peaks', 'light_decelerations', 'histogram_tendency',
    'histogram_number_of_zeroes', 'severe_decelerations', 'baseline value', 'histogram_min'
]
data_dropped = data.drop(columns=features_to_drop)
data_dropped['fetal_health'] = data_dropped['fetal_health'].astype(int)
X = data_dropped.drop(['fetal_health'], axis=1)
y = data_dropped['fetal_health']

# Scale and simulate temporal data
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)
n_time_steps = 5
X_temporal = []
y_temporal = []
for i in range(len(X_scaled)):
    sample = X_scaled.iloc[i].values
    time_series = []
    for t in range(n_time_steps):
        noise = np.random.uniform(-0.05, 0.05, size=sample.shape)
        noisy_sample = np.clip(sample + noise, 0, 1)
        time_series.append(noisy_sample)
    X_temporal.append(time_series)
    y_temporal.append(y.iloc[i])
X_temporal = np.array(X_temporal)
y_temporal = np.array(y_temporal)

# Temporal CTGAN
minority_mask = np.isin(y_temporal, [2, 3])
X_minority_temporal = X_temporal[minority_mask]
y_minority_temporal = y_temporal[minority_mask]
X_minority_flat = X_minority_temporal.reshape(len(X_minority_temporal), -1)
feature_names = [f'f{t}_{col}' for t in range(n_time_steps) for col in X.columns]
data_minority_flat = pd.DataFrame(X_minority_flat, columns=feature_names)
data_minority_flat['fetal_health'] = y_minority_temporal
n_samples_adjusted = (len(data_minority_flat) // 10) * 10
data_minority_trimmed = data_minority_flat.iloc[:n_samples_adjusted]
suspect_data = data_minority_trimmed[data_minority_trimmed['fetal_health'] == 2]
pathological_data = data_minority_trimmed[data_minority_trimmed['fetal_health'] == 3]
ctgan_suspect = CTGAN(epochs=500, batch_size=50, verbose=True, cuda=True)
ctgan_suspect.fit(suspect_data, discrete_columns=['fetal_health'])
ctgan_pathological = CTGAN(epochs=500, batch_size=50, verbose=True, cuda=True)
ctgan_pathological.fit(pathological_data, discrete_columns=['fetal_health'])
n_suspect = 1655 - 295
n_pathological = 1655 - 176
synthetic_suspect = ctgan_suspect.sample(n_suspect)
synthetic_pathological = ctgan_pathological.sample(n_pathological)
synthetic_data = pd.concat([synthetic_suspect, synthetic_pathological], ignore_index=True)
synthetic_flat = synthetic_data.drop('fetal_health', axis=1).values
synthetic_labels = synthetic_data['fetal_health'].values
X_synthetic_temporal = synthetic_flat.reshape(-1, n_time_steps, X_scaled.shape[1])
X_gan_temporal = np.vstack([X_temporal, X_synthetic_temporal])
y_gan_temporal = np.hstack([y_temporal, synthetic_labels])

# Split and flatten
X_train, X_test, y_train, y_test = train_test_split(
    X_gan_temporal, y_gan_temporal, test_size=0.3, random_state=42, stratify=y_gan_temporal
)
X_train_final, X_valid, y_train_final, y_valid = train_test_split(
    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
)
X_train_flat = X_train_final.reshape(-1, n_time_steps * X_scaled.shape[1])
X_valid_flat = X_valid.reshape(-1, n_time_steps * X_scaled.shape[1])
X_test_flat = X_test.reshape(-1, n_time_steps * X_scaled.shape[1])

# Optuna tuning (keep your original function)
def objective(trial: Trial):
    n_d = trial.suggest_int('n_d', 32, 128)
    n_a = trial.suggest_int('n_a', 32, 128)
    n_steps = trial.suggest_int('n_steps', 3, 10)
    gamma = trial.suggest_float('gamma', 1.0, 2.0)
    lambda_sparse = trial.suggest_float('lambda_sparse', 1e-4, 1e-2, log=True)
    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)
    batch_size = trial.suggest_categorical('batch_size', [128, 256, 512])
    tabnet = UncertaintyTabNet(
        input_dim=n_time_steps * X_scaled.shape[1],
        output_dim=3,
        n_d=n_d, n_a=n_a, n_steps=n_steps, gamma=gamma,
        lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam,
        optimizer_params=dict(lr=learning_rate), mask_type='sparsemax', verbose=0
    )
    tabnet.fit(X_train_flat, y_train_final, eval_set=[(X_valid_flat, y_valid)], max_epochs=100, patience=20, batch_size=batch_size)
    y_pred = np.argmax(tabnet.predict_proba(X_valid_flat)[0], axis=1) + 1
    return accuracy_score(y_valid, y_pred)

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)

import numpy as np
import torch
import torch.nn as nn
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming device, study.best_params, X_train_flat, y_train_final, X_valid_flat, y_valid, X_test_flat, y_test are defined earlier
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the augment_data function
def augment_data(X, y, permutation_prob=0.1):
    """
    Augment the dataset by randomly permuting feature orders with a given probability.

    Parameters:
    - X (numpy.ndarray): Feature matrix (e.g., shape (samples, 50) for 5 time steps × 10 features).
    - y (numpy.ndarray): Target vector.
    - permutation_prob (float): Probability of permuting each sample.

    Returns:
    - X_augmented (numpy.ndarray): Augmented feature matrix.
    - y_augmented (numpy.ndarray): Augmented target vector.
    """
    X_augmented = []
    y_augmented = []
    for sample, label in zip(X, y):
        if np.random.rand() < permutation_prob:
            perm = np.random.permutation(sample.shape[0])  # Permute the 50 features
            sample = sample[perm]
        X_augmented.append(sample)
        y_augmented.append(label)
    return np.array(X_augmented), np.array(y_augmented)

# Define UncertaintyTabNet
class UncertaintyTabNet(TabNetClassifier):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.dropout = nn.Dropout(p=0.3).to(device)
        self.training = True
        self.device = device

    def forward(self, x):
        x = torch.tensor(x, dtype=torch.float32).to(self.device)
        if self.training or self.dropout.training:
            x = self.dropout(x)
        return self.network(x)

    def predict_proba(self, X):
        self.network.eval()
        with torch.no_grad():
            X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)
            probs = []
            for _ in range(50):
                self.network.train()
                logits, _ = self.forward(X_tensor)
                prob = torch.softmax(logits, dim=1).cpu().numpy()
                probs.append(prob)
            probs = np.stack(probs, axis=0)
        return np.mean(probs, axis=0), np.std(probs, axis=0)

# Train with best params (study.best_params is from Optuna tuning)
perm_reg_tabnet = UncertaintyTabNet(
    input_dim=n_time_steps * X_scaled.shape[1],  # e.g., 50 (5 time steps × 10 features)
    output_dim=3,
    n_d=study.best_params['n_d'],
    n_a=study.best_params['n_a'],
    n_steps=study.best_params['n_steps'],
    gamma=study.best_params['gamma'],
    lambda_sparse=study.best_params['lambda_sparse'],
    optimizer_fn=torch.optim.Adam,
    optimizer_params={'lr': study.best_params['learning_rate']},
    mask_type='sparsemax',
    verbose=1,
    seed=42
)

# Apply data augmentation
X_train_augmented, y_train_augmented = augment_data(X_train_flat, y_train_final, permutation_prob=0.1)

# Train the model
perm_reg_tabnet.fit(
    X_train=X_train_augmented,
    y_train=y_train_augmented,
    eval_set=[(X_valid_flat, y_valid)],
    eval_name=['valid'],
    eval_metric=['accuracy'],
    max_epochs=100,
    patience=20,
    batch_size=study.best_params['batch_size'],
    virtual_batch_size=128
)

# Evaluate
probs_mean, probs_std = perm_reg_tabnet.predict_proba(X_test_flat)
y_pred_mean = np.argmax(probs_mean, axis=1) + 1  # Adjust back to 1, 2, 3
y_pred_uncertainty = np.max(probs_std, axis=1)

print("\nTemporal Uncertainty-Aware TabNet Classification Report:")
print(classification_report(y_test, y_pred_mean, target_names=['Normal', 'Suspect', 'Pathological']))
print(f"Mean uncertainty: {np.mean(y_pred_uncertainty):.4f}")

# Confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred_mean), annot=True, fmt='d', cmap='Blues',
            xticklabels=['Normal', 'Suspect', 'Pathological'],
            yticklabels=['Normal', 'Suspect', 'Pathological'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Uncertainty distribution
plt.figure(figsize=(8, 6))
sns.histplot(y_pred_uncertainty, bins=20, color='purple')
plt.title('Prediction Uncertainty Distribution')
plt.xlabel('Max Standard Deviation')
plt.show()





















